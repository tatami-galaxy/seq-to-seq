{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import revtok\n",
    "from torchtext.data import BucketIterator\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields for articles(text) and titles(summary)\n",
    "text = data.ReversibleField(sequential=True, tokenize=None, include_lengths=True)\n",
    "summary = data.ReversibleField(sequential=True, tokenize=None, \n",
    "                               include_lengths=True, eos_token='<eos>')\n",
    "\n",
    "# Creating training and validation datasets\n",
    "train, valid = data.TabularDataset.splits(\n",
    "    path='./processed_data/', train='train_dataset.csv',\n",
    "    validation='valid_dataset.csv', skip_header=True, \n",
    "    format='csv', fields=[('article', text), ('title', summary)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embedidngs to build vocabulary\n",
    "#input_vectors = vocab.Vectors('crawl-300d-2M-input.vec')\n",
    "#output_vectors = vocab.Vectors('crawl-300d-2M-output.vec')\n",
    "\n",
    "#text.build_vocab(train, vectors=input_vectors)\n",
    "text.build_vocab(train, vectors='glove.6B.300d')\n",
    "\n",
    "#summary.build_vocab(train, vectors=input_vectors)\n",
    "summary.build_vocab(train, vectors='glove.6B.300d')\n",
    "\n",
    "# Number of dimensions of embeddings\n",
    "num_dims = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Iterator for generating batches\n",
    "train_iter, valid_iter = BucketIterator.splits(\n",
    "    (train, valid), \n",
    "    (batch_size, 1),\n",
    "    device=0,\n",
    "    #sort=True, # sort in ascending order of lenghts\n",
    "    sort_key=lambda x: len(x.article),\n",
    "    sort_within_batch=True, # sort each batch in descending order of article length\n",
    "    repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing embedding of all zeros for UNK with a random embedding\n",
    "_ = torch.nn.init.normal(text.vocab.vectors[0], mean=0, std=0.05) \n",
    "_ = torch.nn.init.normal(summary.vocab.vectors[0], mean=0, std=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embed): Embedding(114618, 300)\n",
       "  (lstm): LSTM(300, 512, num_layers=2)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input vocabulary\n",
    "input_vocab = text.vocab\n",
    "# Number of hidden units in each hidden layer\n",
    "encoder_hidden_size = 512\n",
    "# Number of recurrent layers in model\n",
    "num_layers = 2\n",
    "# Encoder dropout\n",
    "encoder_dropout = 0\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab, hidden_size, dropout):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self._vocab = vocab\n",
    "        self._hidden_size = hidden_size\n",
    "        self._dropout = dropout\n",
    "        \n",
    "        # Hidden layer and cell state of model\n",
    "        # Initialize before calling model\n",
    "        self.hidden = None\n",
    "        \n",
    "        # Lookup table that stores word embeddings\n",
    "        self.embed = nn.Embedding(len(self._vocab), num_dims).cuda()\n",
    "        self.embed.weight.data.copy_(self._vocab.vectors)\n",
    "        self.embed.weight.requires_grad = False\n",
    "        \n",
    "        # Pytorch lstm module\n",
    "        self.lstm = nn.LSTM(num_dims, self._hidden_size, \n",
    "                            num_layers, dropout=self._dropout)\n",
    "        self.lstm.cuda()\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (Variable(torch.cuda.FloatTensor(num_layers, batch_size,\n",
    "                    self._hidden_size).fill_(0), requires_grad=False), \n",
    "                Variable(torch.cuda.FloatTensor(num_layers, batch_size, \n",
    "                    self._hidden_size).fill_(0), \n",
    "                         requires_grad=False))\n",
    "    \n",
    "    def forward(self, batch_data, sequence_lengths):\n",
    "        # Embedding lookup\n",
    "        input = self.embed(batch_data)\n",
    "        # packed_input is of size Txbx*\n",
    "        # where T is the length of longest sequence\n",
    "        # b is batch size\n",
    "        # batch is sorted in descending order of sequence lengths\n",
    "        packed_input = pack_padded_sequence(input, list(sequence_lengths))\n",
    "        packed_output, self.hidden = self.lstm(packed_input, self.hidden)\n",
    "        # Final hidden state\n",
    "        return self.hidden\n",
    "    \n",
    "encoder = EncoderRNN(input_vocab, encoder_hidden_size, encoder_dropout)\n",
    "encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN(\n",
       "  (embed): Embedding(43919, 300)\n",
       "  (cell_list): ModuleList(\n",
       "    (0): LSTMCell(300, 512)\n",
       "    (1): LSTMCell(512, 512)\n",
       "  )\n",
       "  (linear_transform): Linear(in_features=512, out_features=43919, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output vocabulary\n",
    "output_vocab = summary.vocab\n",
    "# Number of hidden units in each hidden layer\n",
    "decoder_hidden_size = 512\n",
    "# Encoder dropout\n",
    "decoder_dropout = 0\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab, hidden_size, dropout):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self._vocab = vocab\n",
    "        self._hidden_size = hidden_size\n",
    "        self._dropout = dropout\n",
    "        \n",
    "        # Lookup table that stores word embeddings\n",
    "        self.embed = nn.Embedding(len(self._vocab), num_dims).cuda()\n",
    "        self.embed.weight.data.copy_(self._vocab.vectors)\n",
    "        self.embed.weight.requires_grad = False\n",
    "    \n",
    "        # Cell and hidden states\n",
    "        self.cell_list = []\n",
    "        self.hidden_list = []\n",
    "    \n",
    "        # First cell takes word embeddings as input\n",
    "        self.cell_list.append(nn.LSTMCell(num_dims, self._hidden_size).cuda())\n",
    "        for cell in range(1, num_layers):\n",
    "            self.cell_list.append(nn.LSTMCell(self._hidden_size, self._hidden_size).cuda())\n",
    "        # ModlueList Holds submodules in a list. \n",
    "        # ModuleList can be indexed like a regular Python list, \n",
    "        # but modules it contains are properly registered, \n",
    "        # and will be visible by all Module methods.\n",
    "        self.cell_list=nn.ModuleList(self.cell_list) \n",
    "        \n",
    "        # Linear transformation \n",
    "        self.linear_transform = nn.Linear(self._hidden_size, len(self._vocab))\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.embed(input) \n",
    "        # Each item in hidden list is a tuple of previous cell and hidden states\n",
    "        for layer in range(num_layers):\n",
    "            self.hidden_list[layer] = self.cell_list[layer](input, self.hidden_list[layer])\n",
    "            input = self.hidden_list[layer][0]\n",
    "        # output has shape (batch_size, vocab_size)\n",
    "        output = self.linear_transform(self.hidden_list[num_layers - 1][0])\n",
    "        return output\n",
    "    \n",
    "decoder = DecoderRNN(output_vocab, decoder_hidden_size, decoder_dropout)\n",
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_distribution(distribution):\n",
    "# Sample one element from a distribution assumed to be an array of normalized probabilities\n",
    "    r = random.uniform(0, 1)\n",
    "    s = 0\n",
    "    for i in range(len(distribution)):\n",
    "        s += distribution[i]\n",
    "        if s >= r:\n",
    "            return i\n",
    "    return len(distribution) - 1\n",
    "\n",
    "def predict_by_sampling(output, batch_size):\n",
    "    output = output.cpu() \n",
    "    next_input = torch.cuda.LongTensor(batch_size)\n",
    "    # output has shape (batch_size, vocab_size)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    output = softmax(output)\n",
    "    for b in range(batch_size): \n",
    "        next_input[b] = sample_distribution(output[b].data)\n",
    "    return Variable(next_input)\n",
    "\n",
    "def most_likely(output, batch_size):\n",
    "    if batch_size > 1:\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        output = softmax(output)\n",
    "        _, next_input = torch.topk(output, 1, dim=1)\n",
    "    else: \n",
    "        softmax = nn.Softmax(dim=0)\n",
    "        output = softmax(output)\n",
    "        _, next_input = torch.topk(output, 1)\n",
    "    return next_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "\n",
    "# Filter parameters that do not require gradients\n",
    "encoder_parameters = filter(lambda p: p.requires_grad, encoder.parameters())\n",
    "decoder_parameters = filter(lambda p: p.requires_grad, decoder.parameters())\n",
    "# Optimizers\n",
    "encoder_optimizer = torch.optim.SGD(encoder_parameters, lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.SGD(decoder_parameters, lr=learning_rate)\n",
    "# Loss function\n",
    "# Way to accumulate loss on sequences with variable lengths in batches :\n",
    "# size_average: By default, the losses are averaged over observations for each minibatch.\n",
    "# However, if the field size_average is set to False, the losses are instead summed for each minibatch. \n",
    "# Ignored if reduce is False.\n",
    "# Set size_average to False and divide the loss by the number of non-padding tokens.\n",
    "# ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient. \n",
    "# When size_average is True, the loss is averaged over non-ignored targets.\n",
    "# Set ignore_index to the padding value\n",
    "loss_function = nn.CrossEntropyLoss(size_average=False, ignore_index=1).cuda() # 1 is the index of <pad>\n",
    "\n",
    "def train_model(batch):\n",
    "    loss = 0\n",
    "    # Clear model gradients\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    # Clear optimizer gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    # Clear hidden state of LSTM\n",
    "    encoder.hidden = encoder.init_hidden(batch_size)\n",
    "    #decoder.hidden1 = decoder.init_hidden(batch_size)\n",
    "    #decoder.hidden2 = decoder.init_hidden(batch_size)\n",
    "    # articles, titles are LongTensor vairables of shape (max_sequence_length, batch_size)\n",
    "    # containig word indices from the respective vocabs\n",
    "    # lengths are LongTensor varibles of shape batch_size containing\n",
    "    # lengths of all the sequences in the batch\n",
    "    articles, art_lengths = batch.article\n",
    "    titles, tit_lengths = batch.title\n",
    "    hiddenT = encoder(articles, art_lengths)\n",
    "    # Seperate hidden states corresponding to the the two layers of the encoder\n",
    "    # and append to hidden state list of decoder as tuples for each layer.\n",
    "    for layer in range(num_layers):\n",
    "        decoder.hidden_list.append((hiddenT[0][layer], hiddenT[1][layer]))\n",
    "    ## replacement for <sos> token. Error? ##\n",
    "    input = Variable(torch.cuda.LongTensor(batch_size).fill_(1)) # 1 is the index of <pad>\n",
    "\n",
    "    # Looping over all the sequences\n",
    "    for t in range(torch.max(tit_lengths)):\n",
    "        output = decoder(input)\n",
    "        #input = predict_by_sampling(output, batch_size)\n",
    "        input = most_likely(output, batch_size)\n",
    "        loss += loss_function(output, titles[t])\n",
    "    \n",
    "    loss = loss/torch.sum(tit_lengths)\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    # Initialize hidden_list for next batch of inputs\n",
    "    decoder.hidden_list = []\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 3 epochs\"\"\"\n",
    "    lr = learning_rate * (0.1 ** (epoch // 3))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average minibatch loss at step 100: 8.635\n",
      "Average minibatch loss at step 200: 7.981\n",
      "Average minibatch loss at step 300: 8.135\n",
      "Average minibatch loss at step 400: 7.660\n",
      "Average minibatch loss at step 500: 7.624\n",
      "Average minibatch loss at step 600: 7.629\n",
      "Average minibatch loss at step 700: 7.477\n",
      "Average minibatch loss at step 800: 7.397\n",
      "Average minibatch loss at step 900: 7.360\n",
      "Average minibatch loss at step 1000: 7.571\n",
      "Average minibatch loss at step 1100: 7.468\n",
      "Average minibatch loss at step 1200: 7.604\n",
      "Average minibatch loss at step 1300: 7.458\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1986cf9f752b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchtext-0.2.1-py3.5.egg/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 yield Batch(minibatch, self.dataset, self.device,\n\u001b[0;32m--> 180\u001b[0;31m                             self.train)\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchtext-0.2.1-py3.5.egg/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device, train)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchtext-0.2.1-py3.5.egg/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device, train)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m    185\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torchtext-0.2.1-py3.5.egg/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device, train)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.fasttest = True\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "step = 1\n",
    "\n",
    "for batch in train_iter:\n",
    "    if torch.max(batch.article[1]) > 80: \n",
    "        step += 1\n",
    "        continue\n",
    "    loss = train_model(batch)\n",
    "    if step % 100 == 0:\n",
    "        print('Average minibatch loss at step %d: %.3f' % (step, loss))\n",
    "    if step % 1000 == 0 and step > 1000:\n",
    "        adjust_learning_rate(encoder_optimizer, step // 1000)\n",
    "        adjust_learning_rate(decoder_optimizer, step // 1000)\n",
    "    step += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, param in encoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
